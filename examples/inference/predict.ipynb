{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having trained a model, you can use the output.yml and an input sequence file to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT BEFORE YOU START\n",
    "\n",
    "The out config will contain absolute paths to directories. In other words: this notebook will likely work if you ran the training and notebook from the same environment (node, cluster or machine), but it will most likely fail to work if you move results from training to a different machine to perform inference/predictions. However, don't worry: there's an easy fix (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from biotrainer.utilities import read_config_file\n",
    "from biotrainer.inference import Inferencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "out_config_path = '../residue_to_class/output/out.yml'\n",
    "out_config = read_config_file(out_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out how well the model performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the CNN, the metrics on the test set are:\n",
      "\t- f1_score class 0 : 0.0\n",
      "\t- f1_score class 1 : 0.0\n",
      "\t- f1_score class 2 : 0.0\n",
      "\t- f1_score class 3 : 0.0\n",
      "\t- f1_score class 4 : 0.0\n",
      "\t- precission class 0 : 0.0\n",
      "\t- precission class 1 : 0.0\n",
      "\t- precission class 2 : 0.0\n",
      "\t- precission class 3 : 0.0\n",
      "\t- precission class 4 : 0.0\n",
      "\t- recall class 0 : 0.0\n",
      "\t- recall class 1 : 0.0\n",
      "\t- recall class 2 : 0.0\n",
      "\t- recall class 3 : 0.0\n",
      "\t- recall class 4 : 0.0\n",
      "\taccuracy : 0.0\n",
      "\tloss : 1.6182039976119995\n",
      "\tmacro-f1_score : 0.0\n",
      "\tmacro-precision : 0.0\n",
      "\tmacro-recall : 0.0\n",
      "\tmatthews-corr-coeff : -0.3000600337982178\n",
      "\tmicro-f1_score : 0.0\n",
      "\tmicro-precision : 0.0\n",
      "\tmicro-recall : 0.0\n",
      "\tspearmans-corr-coeff : -0.14046210050582886\n"
     ]
    }
   ],
   "source": [
    "print(f\"For the {out_config['model_choice']}, the metrics on the test set are:\")\n",
    "for metric in out_config['test_iterations_results']['metrics']:\n",
    "    print(f\"\\t{metric} : {out_config['test_iterations_results']['metrics'][metric]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does the absolute path of the model look correct?**\n",
    "\n",
    "As stated above, the out.yml file will contain absolute paths to files and directories from the biotrainer run. If you move files between machines, these paths may get \"broken\". However, in order to fix this, you juse need to substitute the beginning of the path as stored in the outconfig with the location of where the results are stored now. This is fairly easy, an example is provided below, but needs to be adapted to **your local folder structure**!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute path of biotrainer run output as from config: /home/sebie/PycharmProjects/biotrainerFork/examples/residue_to_class/output\n"
     ]
    }
   ],
   "source": [
    "print(f\"Absolute path of biotrainer run output as from config: {out_config['output_dir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_output_path_root = \"../examples/\"\n",
    "old_output_path_root = \"/mnt/home/cdallago/biotrainer/examples/\"\n",
    "\n",
    "for key in out_config:\n",
    "    if isinstance(out_config[key], str) and old_output_path_root in out_config[key]:\n",
    "        out_config[key] = out_config[key].replace(old_output_path_root, new_output_path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute path of biotrainer run output after swapping the root path: /home/sebie/PycharmProjects/biotrainerFork/examples/residue_to_class/output\n"
     ]
    }
   ],
   "source": [
    "print(f\"Absolute path of biotrainer run output after swapping the root path: {out_config['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create the embeddings for the sequences we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from bio_embeddings.embed import OneHotEncodingEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = OneHotEncodingEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sequences = [\n",
    "    \"PROVTEIN\",\n",
    "    \"SEQVENCESEQVENCE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "embeddings = embedder.embed_many(sequences)\n",
    "# Note that for per-sequence embeddings, you would have to reduce the embeddings now:\n",
    "# embeddings = [[embedder.reduce_per_protein(embedding)] for embedding in embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we generate an inference object from the out config of our training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1 split(s): hold_out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebie/.cache/pypoetry/virtualenvs/biotrainer-_BxfB8Sv-py3.9/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "inferencer = Inferencer(**out_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "predictions = inferencer.from_embeddings(embeddings, split_name=\"hold_out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROVTEIN\n",
      "FFFDFDFF\n",
      "SEQVENCESEQVENCE\n",
      "FFEFFFFFDEFFFFEF\n"
     ]
    }
   ],
   "source": [
    "for sequence, prediction in zip(sequences, predictions.values()):\n",
    "    print(sequence)\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
